dataset$d2 = NULL
dataset$d3 = NULL
dataset$d4 = NULL
dataset$ID = rep(1:210, each = 4)
#NML dataset
NML.dataset = mlogit.data(dataset, choice = "Choice", shape = "long", alt.levels = c("air","train","bus","car"),alt.var = "ChoiceID", chid.var = "ID", drop.index = TRUE)
#NML model
#fit = mFormula(Choice ~ Time + Invc + Invt + Hinc|1)
NMLmodel <- mlogit(Choice ~ Time + Invc + Invt|Hinc, NML.dataset, reflevel = "car" )
summary(NMLmodel)
#load package
library(mlogit)
#load and clean dataset, drop unnecessary columns
setwd("~/R projects")
dataset = read.table("travel.dat")
colnames(dataset) = c("Choice","Time","Invc","Invt","Gc","Chair","Hinc","PSize","d1","d2","d3","d4")
dataset$Chair = NULL
dataset$d1 = NULL
dataset$d2 = NULL
dataset$d3 = NULL
dataset$d4 = NULL
dataset$ID = rep(1:210, each = 4)
#NML dataset
NML.dataset = mlogit.data(dataset, choice = "Choice", shape = "long", alt.levels = c("air","train","bus","car"),alt.var = "ChoiceID", chid.var = "ID", drop.index = TRUE)
#NML model
NMLmodel <- mlogit(Choice ~ Time + Invc + Invt|Hinc, NML.dataset, reflevel = "bus" )
summary(NMLmodel)
#load package
library(mlogit)
#load and clean dataset, drop unnecessary columns
setwd("~/R projects")
dataset = read.table("travel.dat")
colnames(dataset) = c("Choice","Time","Invc","Invt","Gc","Chair","Hinc","PSize","d1","d2","d3","d4")
dataset$Chair = NULL
dataset$d1 = NULL
dataset$d2 = NULL
dataset$d3 = NULL
dataset$d4 = NULL
dataset$ID = rep(1:210, each = 4)
#NML dataset
NML.dataset = mlogit.data(dataset, choice = "Choice", shape = "long", alt.levels = c("air","train","bus","car"),alt.var = "ChoiceID", chid.var = "ID", drop.index = TRUE)
#NML model
NMLmodel <- mlogit(Choice ~ Time  + Invt|Hinc, NML.dataset, reflevel = "bus" )
summary(NMLmodel)
#load package
library(mlogit)
#load and clean dataset, drop unnecessary columns
setwd("~/R projects")
dataset = read.table("travel.dat")
colnames(dataset) = c("Choice","Time","Invc","Invt","Gc","Chair","Hinc","PSize","d1","d2","d3","d4")
dataset$Chair = NULL
dataset$d1 = NULL
dataset$d2 = NULL
dataset$d3 = NULL
dataset$d4 = NULL
dataset$ID = rep(1:210, each = 4)
#NML dataset
NML.dataset = mlogit.data(dataset, choice = "Choice", shape = "long", alt.levels = c("air","train","bus","car"),alt.var = "ChoiceID", chid.var = "ID", drop.index = TRUE)
#NML model
NMLmodel <- mlogit(Choice ~ Time  + Invt|Hinc, NML.dataset, reflevel = "car" )
summary(NMLmodel)
#load package
library(mlogit)
#load and clean dataset, drop unnecessary columns
setwd("~/R projects")
dataset = read.table("travel.dat")
colnames(dataset) = c("Choice","Time","Invc","Invt","Gc","Chair","Hinc","PSize","d1","d2","d3","d4")
dataset$Chair = NULL
dataset$d1 = NULL
dataset$d2 = NULL
dataset$d3 = NULL
dataset$d4 = NULL
dataset$ID = rep(1:210, each = 4)
#NML dataset
NML.dataset = mlogit.data(dataset, choice = "Choice", shape = "long", alt.levels = c("air","train","bus","car"),alt.var = "ChoiceID", chid.var = "ID", drop.index = TRUE)
#NML model
NMLmodel <- mlogit(Choice ~ Time  + Invc + Invt|Hinc, NML.dataset, reflevel = "car" )
summary(NMLmodel)
#load package
library(mlogit)
#load and clean dataset, drop unnecessary columns
setwd("~/R projects")
dataset = read.table("travel.dat")
colnames(dataset) = c("Choice","Time","Invc","Invt","Gc","Chair","Hinc","PSize","d1","d2","d3","d4")
dataset$Chair = NULL
dataset$d1 = NULL
dataset$d2 = NULL
dataset$d3 = NULL
dataset$d4 = NULL
dataset$ID = rep(1:210, each = 4)
#NML dataset
NML.dataset = mlogit.data(dataset, choice = "Choice", shape = "long", alt.levels = c("air","train","bus","car"),alt.var = "ChoiceID", chid.var = "ID", drop.index = TRUE)
#NML model
NMLmodel <- mlogit(Choice ~ Time  + Invt|Hinc, NML.dataset, reflevel = "car" )
summary(NMLmodel)
#load package
library(mlogit)
#load and clean dataset, drop unnecessary columns
setwd("~/R projects")
dataset = read.table("travel.dat")
colnames(dataset) = c("Choice","Time","Invc","Invt","Gc","Chair","Hinc","PSize","d1","d2","d3","d4")
dataset$Chair = NULL
dataset$d1 = NULL
dataset$d2 = NULL
dataset$d3 = NULL
dataset$d4 = NULL
dataset$ID = rep(1:210, each = 4)
#NML dataset
NML.dataset = mlogit.data(dataset, choice = "Choice", shape = "long", alt.levels = c("air","train","bus","car"),alt.var = "ChoiceID", chid.var = "ID", drop.index = TRUE)
#NML model
NMLmodel <- mlogit(Choice ~ Time  + Invt | Hinc, NML.dataset, reflevel = "car" )
summary(NMLmodel)
#load package
library(mlogit)
#load and clean dataset, drop unnecessary columns
setwd("~/R projects")
dataset = read.table("travel.dat")
colnames(dataset) = c("Choice","Time","Invc","Invt","Gc","Chair","Hinc","PSize","d1","d2","d3","d4")
dataset$Chair = NULL
dataset$d1 = NULL
dataset$d2 = NULL
dataset$d3 = NULL
dataset$d4 = NULL
dataset$ID = rep(1:210, each = 4)
#NML dataset
NML.dataset = mlogit.data(dataset, choice = "Choice", shape = "long", alt.levels = c("air","train","bus","car"),alt.var = "ChoiceID", chid.var = "ID", drop.index = TRUE)
#NML model
NMLmodel <- mlogit(Choice ~ Time  + Invt + PSize | Hinc, NML.dataset, reflevel = "car" )
#load package
library(mlogit)
#load and clean dataset, drop unnecessary columns
setwd("~/R projects")
dataset = read.table("travel.dat")
colnames(dataset) = c("Choice","Time","Invc","Invt","Gc","Chair","Hinc","PSize","d1","d2","d3","d4")
dataset$Chair = NULL
dataset$d1 = NULL
dataset$d2 = NULL
dataset$d3 = NULL
dataset$d4 = NULL
dataset$ID = rep(1:210, each = 4)
#NML dataset
NML.dataset = mlogit.data(dataset, choice = "Choice", shape = "long", alt.levels = c("air","train","bus","car"),alt.var = "ChoiceID", chid.var = "ID", drop.index = TRUE)
#NML model
NMLmodel <- mlogit(Choice ~ Time  + PSize + Invt | Hinc, NML.dataset, reflevel = "car" )
NML.dataset
#load package
library(mlogit)
#load and clean dataset, drop unnecessary columns
setwd("~/R projects")
dataset = read.table("travel.dat")
colnames(dataset) = c("Choice","Time","Invc","Invt","Gc","Chair","Hinc","PSize","d1","d2","d3","d4")
dataset$Chair = NULL
dataset$d1 = NULL
dataset$d2 = NULL
dataset$d3 = NULL
dataset$d4 = NULL
dataset$ID = rep(1:210, each = 4)
#NML dataset
NML.dataset = mlogit.data(dataset, choice = "Choice", shape = "long", alt.levels = c("air","train","bus","car"),alt.var = "ChoiceID", chid.var = "ID", drop.index = TRUE)
#NML model
NMLmodel <- mlogit(Choice ~ Time + Gc + Invt | Hinc, NML.dataset, reflevel = "car" )
summary(NMLmodel)
#load package
library(mlogit)
#load and clean dataset, drop unnecessary columns
setwd("~/R projects")
dataset = read.table("travel.dat")
colnames(dataset) = c("Choice","Time","Invc","Invt","Gc","Chair","Hinc","PSize","d1","d2","d3","d4")
dataset$Chair = NULL
dataset$d1 = NULL
dataset$d2 = NULL
dataset$d3 = NULL
dataset$d4 = NULL
dataset$ID = rep(1:210, each = 4)
#NML dataset
NML.dataset = mlogit.data(dataset, choice = "Choice", shape = "long", alt.levels = c("air","train","bus","car"),alt.var = "ChoiceID", chid.var = "ID", drop.index = TRUE)
#NML model
NMLmodel <- mlogit(Choice ~ Time + Invt | Hinc, NML.dataset, reflevel = "car" )
summary(NMLmodel)
options(scipen=999) # turn off scientific notation
set.seed(999) # set seed
data <- read.csv('telco_churn_data.csv', header=TRUE) # read data
data <- within(data, Churn <- relevel(Churn, ref = 'No')) # making sure Churn == 'Yes' is coded as 1 and Churn == 'No' as zero, in binary logistic regression
head(data,5) # take a look at the data
library(e1071)
library(caret)
mean(data$SeniorCitizen)
data = data[1:5000]
data = data[1:5000,]
mean(data$SeniorCitizen)
options(scipen=999) # turn off scientific notation
set.seed(999) # set seed
data <- read.csv('telco_churn_data.csv', header=TRUE) # read data
data <- within(data, Churn <- relevel(Churn, ref = 'No')) # making sure Churn == 'Yes' is coded as 1 and Churn == 'No' as zero, in binary logistic regression
data = data[1:5000,]
head(data,5) # take a look at the data
colnames(data)
set.seed(999) # set seed
model <- glm(Churn ~ .,
data=data,
family=binomial(link = "logit"))
summary(model)
options(scipen=999) # turn off scientific notation
set.seed(999) # set seed
data <- read.csv('telco_churn_data.csv', header=TRUE) # read data
data <- within(data, Churn <- relevel(Churn, ref = 'No')) # making sure Churn == 'Yes' is coded as 1 and Churn == 'No' as zero, in binary logistic regression
data = data[1:5000,]
head(data,5) # take a look at the data
mean(data$SeniorCitizen)
set.seed(999) # set seed
model <- glm(Churn ~ .,
data=data,
family=binomial(link = "logit"))
summary(model)
options(scipen=999) # turn off scientific notation
set.seed(999) # set seed
data <- read.csv('telco_churn_data.csv', header=TRUE) # read data
data <- within(data, Churn <- relevel(Churn, ref = 'No')) # making sure Churn == 'Yes' is coded as 1 and Churn == 'No' as zero, in binary logistic regression
data = data[1:5000,]
data = subset(data, -PhoneService)
head(data,5) # take a look at the data
data = subset(data, -PhoneService)
options(scipen=999) # turn off scientific notation
set.seed(999) # set seed
data <- read.csv('telco_churn_data.csv', header=TRUE) # read data
data <- within(data, Churn <- relevel(Churn, ref = 'No')) # making sure Churn == 'Yes' is coded as 1 and Churn == 'No' as zero, in binary logistic regression
data = data[1:5000,]
data = subset(data, select = -PhoneService)
head(data,5) # take a look at the data
colnames(data)
set.seed(999) # set seed
model <- glm(Churn ~ .,
data=data,
family=binomial(link = "logit"))
summary(model)
data$churn_prob <- predict.glm(model, newdata=data, type="response")
hist(data$churn_prob)
options(scipen=999) # turn off scientific notation
set.seed(999) # set seed
data <- read.csv('telco_churn_data.csv', header=TRUE) # read data
data <- within(data, Churn <- relevel(Churn, ref = 'No')) # making sure Churn == 'Yes' is coded as 1 and Churn == 'No' as zero, in binary logistic regression
data = data[1:5000,]
#data = subset(data, select = -PhoneService)
head(data,5) # take a look at the data
set.seed(999) # set seed
model <- glm(Churn ~ .,
data=data,
family=binomial(link = "logit"))
summary(model)
options(scipen=999) # turn off scientific notation
set.seed(999) # set seed
data <- read.csv('telco_churn_data.csv', header=TRUE) # read data
data <- within(data, Churn <- relevel(Churn, ref = 'No')) # making sure Churn == 'Yes' is coded as 1 and Churn == 'No' as zero, in binary logistic regression
data = data[1:5000,]
data = subset(data, select = -PhoneService)
head(data,5) # take a look at the data
set.seed(999) # set seed
model <- glm(Churn ~ .,
data=data,
family=binomial(link = "logit"))
summary(model)
data$churn_prob <- predict.glm(model, newdata=data, type="response")
hist(data$churn_prob)
library('caret') # may need to install this package first
confusionMatrix(table(1*(data$churn_prob>0.5),1*(data$Churn=='Yes')))
sum(data$churn_prob>0.6) # number of customers with probability of churn strictly greater than 60%
sum(data$churn_prob<0.2) # number of customers with probability of churn strictly greater than 60%
?which.max()
which.max(data$MonthlyCharges)
max(data$churn_prob)
newdata = data[order(chrun_prob)]
newdata = data[order(data$chrun_prob)]
newdata = data[order(chrun_prob),]
sort(data$churn_prob)
data[data$churn_prob == 0.035609314]
data$churn_prob == 0.035609314
which.max(data$churn_prob)
data[1766,]
-model$coefficients[7]/model$coefficients[10]
options(scipen=999) # turn off scientific notation
set.seed(999) # set seed
data <- read.csv('telco_churn_data.csv', header=TRUE) # read data
data <- within(data, Churn <- relevel(Churn, ref = 'No')) # making sure Churn == 'Yes' is coded as 1 and Churn == 'No' as zero, in binary logistic regression
data = data[1:5000,]
data = subset(data, select = -PhoneService)
head(data,5) # take a look at the data
colnames(data)
set.seed(999) # set seed
model <- glm(Churn ~ .,
data=data,
family=binomial(link = "logit"))
summary(model)
data$churn_prob <- predict.glm(model, newdata=data, type="response")
hist(data$churn_prob)
library('caret') # may need to install this package first
confusionMatrix(table(1*(data$churn_prob>0.5),1*(data$Churn=='Yes')))
sum(data$churn_prob<0.2) # number of customers with probability of churn strictly greater than 60%
-model$coefficients[7]/model$coefficients[10]
-model$coefficients[6]/model$coefficients[9]
-model$coefficients[9]/model$coefficients[6]
library('caret') # may need to install this package first
confusionMatrix(table(1*(data$churn_prob>0.5),1*(data$Churn=='Yes')))
pf
pf(1.0, data)
pf<-function(incr, data)
{
d <- data[data$Churn=="No",] # only keeping customers that have not churned yet
d$MonthlyCharges <- d$MonthlyCharges*incr # possible increase in monthly charges (no increase is incr==1.0)
g <- 0.97 # discount factor (money in the next period is worth 0.99 money in the period before that)
p <- 1-predict.glm(model, newdata=d, type="response") # retention probability based on logistic regresion (we assume retention probability will remain constant for each consumer, conditional on fixed d$MonthlyCharges)
clv <- d$MonthlyCharges/(1-p*g) # CLV formula
return(sum(clv)) # sum of discounted profits across all individual consumers
}
options(scipen=999) # turn off scientific notation
set.seed(999) # set seed
data <- read.csv('telco_churn_data.csv', header=TRUE) # read data
data <- within(data, Churn <- relevel(Churn, ref = 'No')) # making sure Churn == 'Yes' is coded as 1 and Churn == 'No' as zero, in binary logistic regression
data = data[1:5000,]
data = subset(data, select = -PhoneService)
head(data,5) # take a look at the data
colnames(data)
set.seed(999) # set seed
model <- glm(Churn ~ .,
data=data,
family=binomial(link = "logit"))
summary(model)
data$churn_prob <- predict.glm(model, newdata=data, type="response")
hist(data$churn_prob)
library('caret') # may need to install this package first
confusionMatrix(table(1*(data$churn_prob>0.5),1*(data$Churn=='Yes')))
sum(data$churn_prob<0.2) # number of customers with probability of churn strictly greater than 60%
-model$coefficients[9]/model$coefficients[6]
pf<-function(incr, data)
{
d <- data[data$Churn=="No",] # only keeping customers that have not churned yet
d$MonthlyCharges <- d$MonthlyCharges*incr # possible increase in monthly charges (no increase is incr==1.0)
g <- 0.97 # discount factor (money in the next period is worth 0.99 money in the period before that)
p <- 1-predict.glm(model, newdata=d, type="response") # retention probability based on logistic regresion (we assume retention probability will remain constant for each consumer, conditional on fixed d$MonthlyCharges)
clv <- d$MonthlyCharges/(1-p*g) # CLV formula
return(sum(clv)) # sum of discounted profits across all individual consumers
}
pf(1.0, data)
pf(1.0, data) # no increase in price: 1 * charge_amount
pf(1.5, data) # 50% increase: (1 + 0.5) * charge_amount
pf(2, data) # 100% increase / doubling: 2 * charge_amount
pf(3, data) # 200% increase / trippling: 3 * charge_amount
set.seed(999)
opt<-optim(1.0, pf, method="L-BFGS-B", control=list(fnscale=-1), data=data)
c(opt$par, opt$value)
pf(opt$par, data) - pf(1.0, data)
set.seed(999)
opt<-optim(1.0, pf, method="L-BFGS-B", control=list(fnscale=-1), data=data)
c(opt$par, opt$value)
data[4,]
pf(1.0, data) # no increase in price: 1 * charge_amount
pf(1.2, data) # 50% increase: (1 + 0.5) * charge_amount
pf(0.8, data) # 100% increase / doubling: 2 * charge_amount
pf(3, data) # 200% increase / trippling: 3 * charge_amount
0.925^4
0.982^4
0.943^4
0.918^4
install.packages("ISLR")
install.packages("glmnet")
install.packages("shiny")
library(ISLR)
library(glmnet)
Hitters = ISLR::Hitters
Hiters = na.omit(Hitters)
x = model.matrix(Salary~.,Hitters)[, -1]
y = Hitters$Salary
x
y
shiny::runApp('GitHub/Fall2017-project2-grp6/app')
install.packages("tigris")
runApp('GitHub/Fall2017-project2-grp6/app')
remove.packages("tigris")
install.packages("tigris")
runApp('GitHub/Fall2017-project2-grp6/app')
install.packages("sf")
install.packages("sf")
shiny::runApp('GitHub/Fall2017-project2-grp6/app')
sessionInfo()
install.packages("sf")
shiny::runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Fall2017-project2-grp6/app')
runApp('~/GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
?dataTableOutput
??dataTableOutput
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
install.packages("vcd")
install.packages("brrom")
install.packages("broom")
install.packages("broom")
shiny::runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
runApp('GitHub/Spring2019-Proj2-grp8/app')
shiny::runApp('GitHub/Spring2019-Proj2-grp8/apps')
library(shinyBS)
source('C:/Users/Zixiao/AppData/Local/Temp/Temp1_DSAA_Calculator[3446].zip/DSAA_Calculator/ui.R')
runApp('E:/SiriusXM/DSAA_Calculator')
pwr.prop.test
?power.prop.test
power.prop.test(n = 250000, p1 = 0.2286, sig.level = 0.05, power = 0.8, alternative = "two.side")
power.prop.test(n = 250000, p2 = 0.2286, sig.level = 0.05, power = 0.8, alternative = "two.side")
power.prop.test(, p1 = 0.2494,p2 = 0.2286, sig.level = 0.05, power = 0.8, alternative = "two.side")
power.prop.test(, p2 = 0.2494,p1 = 0.2286, sig.level = 0.05, power = 0.8, alternative = "two.side")
power.prop.test(, p2 = 0.2494,p1 = 0.2286, sig.level = 0.05, power = 0.8, alternative = "two.side", strict = TRUE)
(1-0.2286)*0.2286/250000+(1-0.225293)*0.225293/250000
(1-0.2329186)*0.2329186*250000
(1-0.2329186)*0.2329186
is_this_df = as.matrix(is_this_df)
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
set.seed(2018)
setwd("./ads_fall2018_proj3")
setwd("~/GitHub/Spring2019-Proj3-spring2019-proj3-grp4")
set.seed(2018)
# here replace it with your own path or manually set it in RStudio to where this rmd file is located.
# use relative path for reproducibility
train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
model_values <- seq(3, 11, 2)
model_labels = paste("GBM with depth =", model_values)
extra_label <- read.csv(train_label_path, colClasses=c("NULL", NA, NA))
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
#save(dat_train, file="./output/feature_train.RData")
save(dat_train, file="./output/feature_train.RData")
